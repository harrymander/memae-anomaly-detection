{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import TypeVar\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Dataset, Subset, random_split\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('WARNING: not using CUDA')\n",
    "\n",
    "\n",
    "class MNISTDataSet(MNIST):\n",
    "    def __init__(self, train: bool):\n",
    "        super().__init__(\n",
    "            '../.data',\n",
    "            train=train,\n",
    "            download=True,\n",
    "            transform=transforms.ToTensor(),\n",
    "        )\n",
    "\n",
    "T = TypeVar('T')\n",
    "\n",
    "def extract_single_target_class(dataset: Dataset[T], target, targets=None) -> tuple[Subset[T], Subset[T]]:\n",
    "    \"\"\"Returns a subset of dataset containing only samples with target class, and a subset containing all other samples.\"\"\"\n",
    "    indices = np.arange(len(dataset))\n",
    "    mask = dataset.targets == target\n",
    "    return Subset(dataset, indices[mask]), Subset(dataset, indices[~mask])\n",
    "\n",
    "NORMAL_TARGET_CLASS = 5\n",
    "\n",
    "testing_normal_set, testing_outlier_set = extract_single_target_class(\n",
    "    MNISTDataSet(train=False), NORMAL_TARGET_CLASS\n",
    ")\n",
    "training_normal_set, training_outlier_set = extract_single_target_class(\n",
    "    MNISTDataSet(train=True), NORMAL_TARGET_CLASS\n",
    ")\n",
    "\n",
    "# Further split the 'training' set into 2:1 ratio\n",
    "training_set, testing_normal_set_from_training_set = random_split(\n",
    "    training_normal_set, [2/3, 1/3]\n",
    ")\n",
    "\n",
    "testing_normal_set = ConcatDataset((testing_normal_set, testing_normal_set_from_training_set))\n",
    "testing_outlier_set = ConcatDataset((testing_outlier_set, training_outlier_set))\n",
    "testing_set = ConcatDataset((testing_normal_set, testing_outlier_set))\n",
    "\n",
    "print(f'Training set (normal only):        {len(training_set)} samples')\n",
    "print(f'Testing set (normal only):         {len(testing_normal_set)} samples')\n",
    "print(f'Testing set (outliers only):       {len(testing_outlier_set)} samples')\n",
    "print(f'Testing set (normal and outliers): {len(testing_set)} samples')\n",
    "print(f'Total:                             {len(training_set) + len(testing_set)} samples')\n",
    "\n",
    "training_loader = DataLoader(training_set, batch_size=32, shuffle=False)\n",
    "\n",
    "# Show first 5 samples from training and testing outlier sets\n",
    "axes = plt.subplots(2, 5)[1]\n",
    "for ax, image in zip(axes[0], training_set):\n",
    "    ax.imshow(image[0][0])\n",
    "    ax.axis('off')\n",
    "for ax, image in zip(axes[1], testing_outlier_set):\n",
    "    ax.imshow(image[0][0])\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Use the same encoder architecture as in the paper:\n",
    "        conv_layers = [\n",
    "            nn.Conv2d(1, 16, kernel_size=1, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2),\n",
    "        ]\n",
    "\n",
    "        modules = []\n",
    "        for conv_layer in conv_layers:\n",
    "            modules.extend((\n",
    "                conv_layer,\n",
    "                nn.BatchNorm2d(conv_layer.out_channels),\n",
    "                nn.ReLU(),\n",
    "            ))\n",
    "\n",
    "        self.sequence = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequence(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        deconv_layers = [\n",
    "            nn.ConvTranspose2d(64, 64, kernel_size=3, stride=2, output_padding=1),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2),\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=3, stride=2, output_padding=1),\n",
    "        ]\n",
    "\n",
    "        modules = []\n",
    "        for deconv_layer in deconv_layers[:-1]:\n",
    "            modules.extend((\n",
    "                deconv_layer,\n",
    "                nn.BatchNorm2d(num_features=deconv_layer.out_channels),\n",
    "                nn.ReLU(),\n",
    "            ))\n",
    "\n",
    "        modules.append(deconv_layers[-1])\n",
    "        self.sequence = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequence(x)\n",
    "\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "\n",
    "def hard_shrink_relu(input, lambd=0, epsilon=1e-12):\n",
    "    output = (F.relu(input-lambd) * input) / (torch.abs(input - lambd) + epsilon)\n",
    "    return output\n",
    "\n",
    "\n",
    "class MemoryUnit(nn.Module):\n",
    "    \"\"\"From https://github.com/YUL-git/MemAE\"\"\"\n",
    "    def __init__(self, mem_dim, fea_dim, shrink_thres):\n",
    "        super().__init__()\n",
    "        self.mem_dim = mem_dim\n",
    "        self.fea_dim = fea_dim\n",
    "        self.weight = Parameter(torch.Tensor(self.mem_dim, self.fea_dim)) # N x C\n",
    "        self.shrink_thres = shrink_thres\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, x):\n",
    "        att_weight = F.linear(x, self.weight)  # Fea x Mem^T, (TxC) x (CxN) = TxN\n",
    "        att_weight = F.softmax(att_weight, dim=1)  # TxN , 논문에선 1xN\n",
    "\n",
    "        if self.shrink_thres > 0:\n",
    "            att_weight = hard_shrink_relu(att_weight, lambd=self.shrink_thres)\n",
    "            att_weight = F.normalize(att_weight, p=1, dim=1) # Re-normalize, TxN\n",
    "\n",
    "        mem_trans = self.weight.permute(1, 0)  # Mem^T, CxN\n",
    "        output = F.linear(att_weight, mem_trans)  # AttWeight x Mem^T^T = AW x Mem, (TxN) x (NxC) = TxC\n",
    "        return {'output': output, 'att': att_weight}  # output, att_weight\n",
    "\n",
    "\n",
    "# NxCxHxW -> (NxHxW)xC -> addressing Mem, (NxHxW)xC -> NxCxHxW\n",
    "class MemModule(nn.Module):\n",
    "    \"\"\"From https://github.com/YUL-git/MemAE\"\"\"\n",
    "    def __init__(self, mem_dim, fea_dim, shrink_thres=0.02):\n",
    "        super().__init__()\n",
    "        self.mem_dim = mem_dim\n",
    "        self.fea_dim = fea_dim\n",
    "        self.shrink_thres = shrink_thres\n",
    "        self.memory = MemoryUnit(self.mem_dim, self.fea_dim, self.shrink_thres)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, channel, row, col = x.shape\n",
    "        x = x.permute(0, 2, 3, 1) # (B, row, col, channel)\n",
    "        x = x.contiguous()\n",
    "        x = x.view(-1, channel) # (B x row x col, channel)\n",
    "\n",
    "        y_and = self.memory(x)\n",
    "        y = y_and['output']\n",
    "        att = y_and['att']\n",
    "\n",
    "        y = y.view(batch, row, col, channel)\n",
    "        y = y.permute(0, 3, 1, 2) # (B, channel, row, col)\n",
    "        att = att.view(batch, row, col, self.mem_dim)\n",
    "        att = att.permute(0, 3, 1, 2)\n",
    "\n",
    "        return {'output': y, 'att': att}\n",
    "\n",
    "\n",
    "class MemoryAugmentedAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "        # Paper uses a memory size of 100 for MNIST\n",
    "        self.memory_module = MemModule(mem_dim=100, fea_dim=64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mem = self.memory_module(self.encoder(x))\n",
    "        return {\n",
    "            'output': self.decoder(mem['output']),\n",
    "            'att': mem['att'],\n",
    "        }\n",
    "\n",
    "\n",
    "class EntropyLoss(nn.Module):\n",
    "    def __init__(self, eps = 1e-12):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        b = x * torch.log(x + self.eps)\n",
    "        b = -1.0 * b.sum(dim=1)\n",
    "        b = b.mean()\n",
    "        return b\n",
    "\n",
    "\n",
    "# According to paper, alpha = 0.0002 led to desirable results in all experiments\n",
    "class MSEEntropyLoss(nn.Module):\n",
    "    def __init__(self, alpha: float = 0.0002):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.entropy_loss = EntropyLoss()\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        reconstruction_loss = self.mse(output['output'], target)\n",
    "        entropy_loss = self.entropy_loss(output['att'])\n",
    "        return reconstruction_loss + self.alpha * entropy_loss\n",
    "\n",
    "\n",
    "display(AutoEncoder())\n",
    "display(MemoryAugmentedAutoEncoder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(\n",
    "        self, *,\n",
    "        model: nn.Module,\n",
    "        dataloader: DataLoader,\n",
    "        loss_fn: nn.Module,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        num_epoch: int,\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.dataloader = dataloader\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.num_epoch = num_epoch\n",
    "\n",
    "    def train(self) -> nn.Module:\n",
    "        self.model.train(True)\n",
    "        with tqdm(\n",
    "            range(self.num_epoch),\n",
    "            total=self.num_epoch,\n",
    "            desc='Training',\n",
    "            unit='epoch',\n",
    "        ) as pbar:\n",
    "            for epoch in pbar:\n",
    "                avg_loss = self._train_one_epoch(epoch, self.num_epoch)\n",
    "                pbar.set_postfix({'Avg. loss': avg_loss})\n",
    "\n",
    "        return self.model\n",
    "\n",
    "    def _train_one_epoch(self, epoch_index, num_epoch):\n",
    "            # Adapted for autoencoder from:\n",
    "            # https://pytorch.org/tutorials/beginner/introyt/trainingyt.html\n",
    "\n",
    "            training_loss = 0\n",
    "            with tqdm(\n",
    "                self.dataloader,\n",
    "                desc=f'Epoch {epoch_index + 1}/{num_epoch}',\n",
    "                unit='batch',\n",
    "                leave=False,\n",
    "            ) as pbar:\n",
    "                for data, _ in pbar:\n",
    "                    data = data.to(device) # not sure if this is the best way to do this?\n",
    "                    reconstructed = self.model(data)\n",
    "                    loss = self.loss_fn(reconstructed, data)\n",
    "\n",
    "                    self.optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "\n",
    "                    training_loss += loss.item()\n",
    "                    pbar.set_postfix({'Loss': loss.item()})\n",
    "\n",
    "            return training_loss / len(self.dataloader)\n",
    "\n",
    "ae_model = AutoEncoder().to(device)\n",
    "ae_model = ModelTrainer(\n",
    "    model=ae_model,\n",
    "    dataloader=training_loader,\n",
    "    loss_fn=nn.MSELoss(),\n",
    "    optimizer=torch.optim.Adam(ae_model.parameters(), lr=0.0001),\n",
    "    num_epoch=60,\n",
    ").train()\n",
    "\n",
    "memae_model = MemoryAugmentedAutoEncoder().to(device)\n",
    "memae_model = ModelTrainer(\n",
    "    model=memae_model,\n",
    "    dataloader=training_loader,\n",
    "    loss_fn=MSEEntropyLoss(),\n",
    "    optimizer=torch.optim.Adam(memae_model.parameters(), lr=0.0001),\n",
    "    num_epoch=60,\n",
    ").train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemGetter(nn.Module):\n",
    "    def __init__(self, key):\n",
    "        super().__init__()\n",
    "        self.key = key\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[self.key]\n",
    "\n",
    "memae_model_output = nn.Sequential(memae_model, ItemGetter('output'))\n",
    "\n",
    "def plot_reconstruction(image):\n",
    "    ae_model.eval()\n",
    "    memae_model_output.eval()\n",
    "\n",
    "    image = torch.unsqueeze(image, 0)\n",
    "    with torch.no_grad():\n",
    "        ae_recon = ae_model(image.to(device))\n",
    "        memae_recon = memae_model_output(image.to(device))\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3)\n",
    "    axes[0].imshow(image[0][0])\n",
    "    axes[0].set_title('Original')\n",
    "    axes[1].imshow(ae_recon[0][0].cpu().numpy())\n",
    "    axes[1].set_title('AE reconstruction')\n",
    "    axes[2].imshow(memae_recon[0][0].cpu().numpy())\n",
    "    axes[2].set_title('MemAE reconstruction')\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.axis('off')\n",
    "\n",
    "plot_reconstruction(training_set[0][0])\n",
    "plot_reconstruction(testing_normal_set[10][0])\n",
    "plot_reconstruction(testing_outlier_set[10][0])\n",
    "plot_reconstruction(testing_outlier_set[20][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model):\n",
    "    y_score = []\n",
    "    y_true = []\n",
    "    model.eval()\n",
    "    testing_loader = DataLoader(testing_set, batch_size=256)\n",
    "    for data, target in tqdm(testing_loader, total=len(testing_loader), unit='batch'):\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            recon = model(data)\n",
    "            true = (target == NORMAL_TARGET_CLASS).cpu().numpy().astype(int)\n",
    "\n",
    "            # Lower MSE = higher score, so negate the value\n",
    "            score = -((recon - data)**2).mean(dim=(1, 2, 3)).cpu().numpy()\n",
    "\n",
    "        y_true.extend(true)\n",
    "        y_score.extend(score)\n",
    "\n",
    "    return np.asarray(y_true), np.asarray(y_score)\n",
    "\n",
    "ae_y_true, ae_y_score = validate_model(ae_model)\n",
    "memae_y_true, memae_y_score = validate_model(memae_model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "def plot_roc(y_true, y_score, name):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "    auc = roc_auc_score(y_true, y_score)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:g})')\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "\n",
    "plot_roc(ae_y_true, ae_y_score, 'AE')\n",
    "plot_roc(memae_y_true, memae_y_score, 'MemAE')\n",
    "plt.legend()\n",
    "plt.gca().set_aspect(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "memae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
