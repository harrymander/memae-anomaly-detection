{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypeVar\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torch import nn\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('WARNING: not using CUDA')\n",
    "\n",
    "\n",
    "class MNISTDataSet(MNIST):\n",
    "    def __init__(self, train: bool):\n",
    "        super().__init__(\n",
    "            '../.data',\n",
    "            train=train,\n",
    "            download=True,\n",
    "            transform=transforms.ToTensor(),\n",
    "        )\n",
    "\n",
    "class MNISTDataLoader(DataLoader):\n",
    "    def __init__(self, dataset: Dataset):\n",
    "        super().__init__(\n",
    "            dataset,\n",
    "            batch_size=32,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Use the same encoder architecture as in the paper:\n",
    "        conv_layers = [\n",
    "            nn.Conv2d(1, 16, kernel_size=1, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2),\n",
    "        ]\n",
    "\n",
    "        modules = []\n",
    "        for conv_layer in conv_layers:\n",
    "            modules.extend((\n",
    "                conv_layer,\n",
    "                nn.BatchNorm2d(conv_layer.out_channels),\n",
    "                nn.ReLU(),\n",
    "            ))\n",
    "\n",
    "        self.sequence = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequence(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        deconv_layers = [\n",
    "            nn.ConvTranspose2d(64, 64, kernel_size=3, stride=2, output_padding=1),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2),\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=3, stride=2, output_padding=1),\n",
    "        ]\n",
    "\n",
    "        modules = []\n",
    "        for deconv_layer in deconv_layers[:-1]:\n",
    "            modules.extend((\n",
    "                deconv_layer,\n",
    "                nn.BatchNorm2d(num_features=deconv_layer.out_channels),\n",
    "                nn.ReLU(),\n",
    "            ))\n",
    "\n",
    "        modules.append(deconv_layers[-1])\n",
    "        self.sequence = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequence(x)\n",
    "\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "T = TypeVar('T')\n",
    "\n",
    "def extract_single_target_class(dataset: Dataset[T], target, targets=None) -> tuple[Subset[T], Subset[T]]:\n",
    "    \"\"\"Returns a subset of dataset containing only samples with target class, and a subset containing all other samples.\"\"\"\n",
    "    indices = np.arange(len(dataset))\n",
    "    mask = dataset.targets == target\n",
    "    return Subset(dataset, indices[mask]), Subset(dataset, indices[~mask])\n",
    "\n",
    "NORMAL_TARGET_CLASS = 3\n",
    "\n",
    "testing_dataset_normal, testing_dataset_outliers = extract_single_target_class(MNISTDataSet(train=False), NORMAL_TARGET_CLASS)\n",
    "training_dataset, outliers_from_training_set = extract_single_target_class(MNISTDataSet(train=True), NORMAL_TARGET_CLASS)\n",
    "print(f'Training set (normal only): {len(training_dataset)} samples')\n",
    "\n",
    "training_loader = MNISTDataLoader(training_dataset)\n",
    "\n",
    "# Show first 5 samples from training set\n",
    "axes = plt.subplots(1, 5)[1]\n",
    "for ax, image in zip(axes, training_dataset):\n",
    "    ax.imshow(image[0][0])\n",
    "    ax.axis('off')\n",
    "\n",
    "display(AutoEncoder())\n",
    "\n",
    "output_shape = AutoEncoder()(training_dataset[0][0].reshape(1, 1, 28, 28)).shape[1:]\n",
    "assert output_shape == (1, 28, 28), output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(\n",
    "        self, *,\n",
    "        model: nn.Module,\n",
    "        dataloader: DataLoader,\n",
    "        loss_fn: nn.Module,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        num_epoch: int,\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.dataloader = dataloader\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.num_epoch = num_epoch\n",
    "\n",
    "    def train(self) -> nn.Module:\n",
    "        self.model.train(True)\n",
    "        with tqdm(\n",
    "            range(self.num_epoch),\n",
    "            total=self.num_epoch,\n",
    "            desc='Training',\n",
    "            unit='epoch',\n",
    "        ) as pbar:\n",
    "            for epoch in pbar:\n",
    "                avg_loss = self._train_one_epoch(epoch, self.num_epoch)\n",
    "                pbar.set_postfix({'Avg. loss': avg_loss})\n",
    "\n",
    "        return self.model\n",
    "\n",
    "    def _train_one_epoch(self, epoch_index, num_epoch):\n",
    "            # Adapted for autoencoder from:\n",
    "            # https://pytorch.org/tutorials/beginner/introyt/trainingyt.html\n",
    "\n",
    "            training_loss = 0\n",
    "            with tqdm(\n",
    "                self.dataloader,\n",
    "                desc=f'Epoch {epoch_index + 1}/{num_epoch}',\n",
    "                unit='batch',\n",
    "                leave=False,\n",
    "            ) as pbar:\n",
    "                for data, _ in pbar:\n",
    "                    data = data.to(device) # not sure if this is the best way to do this?\n",
    "                    self.optimizer.zero_grad()\n",
    "                    reconstructed = self.model(data)\n",
    "                    loss = self.loss_fn(reconstructed, data)\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "                    training_loss += loss.item()\n",
    "                    pbar.set_postfix({'Loss': loss.item()})\n",
    "\n",
    "            return training_loss / len(training_loader)\n",
    "\n",
    "model=AutoEncoder().to(device)\n",
    "model = ModelTrainer(\n",
    "    model=model,\n",
    "    dataloader=training_loader,\n",
    "    loss_fn=nn.MSELoss(),\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=0.0001),\n",
    "    num_epoch=30,\n",
    ").train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reconstruction(image):\n",
    "    model.eval()\n",
    "\n",
    "    image = torch.unsqueeze(image, 0)\n",
    "    with torch.no_grad():\n",
    "        recon = model(image.to(device))\n",
    "\n",
    "    axes = plt.subplots(1, 2)[1]\n",
    "    axes[0].imshow(image[0][0])\n",
    "    axes[0].set_title('Original')\n",
    "    axes[1].imshow(recon[0][0].cpu().numpy())\n",
    "    axes[1].set_title('Reconstructed')\n",
    "    for ax in axes:\n",
    "        ax.axis('off')\n",
    "\n",
    "plot_reconstruction(training_dataset[0][0])\n",
    "plot_reconstruction(outliers_from_training_set[10][0])\n",
    "plot_reconstruction(testing_dataset_normal[10][0])\n",
    "plot_reconstruction(testing_dataset_outliers[60][0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "memae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
