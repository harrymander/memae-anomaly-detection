{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypeVar\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Dataset, Subset, random_split\n",
    "from torch import nn\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('WARNING: not using CUDA')\n",
    "\n",
    "\n",
    "class MNISTDataSet(MNIST):\n",
    "    def __init__(self, train: bool):\n",
    "        super().__init__(\n",
    "            '../.data',\n",
    "            train=train,\n",
    "            download=True,\n",
    "            transform=transforms.ToTensor(),\n",
    "        )\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Use the same encoder architecture as in the paper:\n",
    "        conv_layers = [\n",
    "            nn.Conv2d(1, 16, kernel_size=1, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2),\n",
    "        ]\n",
    "\n",
    "        modules = []\n",
    "        for conv_layer in conv_layers:\n",
    "            modules.extend((\n",
    "                conv_layer,\n",
    "                nn.BatchNorm2d(conv_layer.out_channels),\n",
    "                nn.ReLU(),\n",
    "            ))\n",
    "\n",
    "        self.sequence = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequence(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        deconv_layers = [\n",
    "            nn.ConvTranspose2d(64, 64, kernel_size=3, stride=2, output_padding=1),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2),\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=3, stride=2, output_padding=1),\n",
    "        ]\n",
    "\n",
    "        modules = []\n",
    "        for deconv_layer in deconv_layers[:-1]:\n",
    "            modules.extend((\n",
    "                deconv_layer,\n",
    "                nn.BatchNorm2d(num_features=deconv_layer.out_channels),\n",
    "                nn.ReLU(),\n",
    "            ))\n",
    "\n",
    "        modules.append(deconv_layers[-1])\n",
    "        self.sequence = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequence(x)\n",
    "\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "T = TypeVar('T')\n",
    "\n",
    "def extract_single_target_class(dataset: Dataset[T], target, targets=None) -> tuple[Subset[T], Subset[T]]:\n",
    "    \"\"\"Returns a subset of dataset containing only samples with target class, and a subset containing all other samples.\"\"\"\n",
    "    indices = np.arange(len(dataset))\n",
    "    mask = dataset.targets == target\n",
    "    return Subset(dataset, indices[mask]), Subset(dataset, indices[~mask])\n",
    "\n",
    "NORMAL_TARGET_CLASS = 3\n",
    "\n",
    "testing_normal_set, testing_outlier_set = extract_single_target_class(\n",
    "    MNISTDataSet(train=False), NORMAL_TARGET_CLASS\n",
    ")\n",
    "training_normal_set, training_outlier_set = extract_single_target_class(\n",
    "    MNISTDataSet(train=True), NORMAL_TARGET_CLASS\n",
    ")\n",
    "\n",
    "# Further split the 'training' set into\n",
    "training_set, testing_normal_set_from_training_set = random_split(\n",
    "    training_normal_set, [2/3, 1/3]\n",
    ")\n",
    "\n",
    "testing_normal_set = ConcatDataset((testing_normal_set, testing_normal_set_from_training_set))\n",
    "testing_outlier_set = ConcatDataset((testing_outlier_set, training_outlier_set))\n",
    "testing_set = ConcatDataset((testing_normal_set, testing_outlier_set))\n",
    "\n",
    "print(f'Training set (normal only):        {len(training_set)} samples')\n",
    "print(f'Testing set (normal only):         {len(testing_normal_set)} samples')\n",
    "print(f'Testing set (outliers only):       {len(testing_outlier_set)} samples')\n",
    "print(f'Testing set (normal and outliers): {len(testing_set)} samples')\n",
    "print(f'Total:                             {len(training_set) + len(testing_set)} samples')\n",
    "\n",
    "training_loader = DataLoader(training_set, batch_size=32, shuffle=False)\n",
    "\n",
    "# Show first 5 samples from training and testing outlier sets\n",
    "axes = plt.subplots(2, 5)[1]\n",
    "for ax, image in zip(axes[0], training_set):\n",
    "    ax.imshow(image[0][0])\n",
    "    ax.axis('off')\n",
    "for ax, image in zip(axes[1], testing_outlier_set):\n",
    "    ax.imshow(image[0][0])\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "\n",
    "display(AutoEncoder())\n",
    "\n",
    "output_shape = AutoEncoder()(training_set[0][0].reshape(1, 1, 28, 28)).shape[1:]\n",
    "assert output_shape == (1, 28, 28), output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(\n",
    "        self, *,\n",
    "        model: nn.Module,\n",
    "        dataloader: DataLoader,\n",
    "        loss_fn: nn.Module,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        num_epoch: int,\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.dataloader = dataloader\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.num_epoch = num_epoch\n",
    "\n",
    "    def train(self) -> nn.Module:\n",
    "        self.model.train(True)\n",
    "        with tqdm(\n",
    "            range(self.num_epoch),\n",
    "            total=self.num_epoch,\n",
    "            desc='Training',\n",
    "            unit='epoch',\n",
    "        ) as pbar:\n",
    "            for epoch in pbar:\n",
    "                avg_loss = self._train_one_epoch(epoch, self.num_epoch)\n",
    "                pbar.set_postfix({'Avg. loss': avg_loss})\n",
    "\n",
    "        return self.model\n",
    "\n",
    "    def _train_one_epoch(self, epoch_index, num_epoch):\n",
    "            # Adapted for autoencoder from:\n",
    "            # https://pytorch.org/tutorials/beginner/introyt/trainingyt.html\n",
    "\n",
    "            training_loss = 0\n",
    "            with tqdm(\n",
    "                self.dataloader,\n",
    "                desc=f'Epoch {epoch_index + 1}/{num_epoch}',\n",
    "                unit='batch',\n",
    "                leave=False,\n",
    "            ) as pbar:\n",
    "                for data, _ in pbar:\n",
    "                    data = data.to(device) # not sure if this is the best way to do this?\n",
    "                    self.optimizer.zero_grad()\n",
    "                    reconstructed = self.model(data)\n",
    "                    loss = self.loss_fn(reconstructed, data)\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "                    training_loss += loss.item()\n",
    "                    pbar.set_postfix({'Loss': loss.item()})\n",
    "\n",
    "            return training_loss / len(training_loader)\n",
    "\n",
    "model=AutoEncoder().to(device)\n",
    "model = ModelTrainer(\n",
    "    model=model,\n",
    "    dataloader=training_loader,\n",
    "    loss_fn=nn.MSELoss(),\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=0.0001),\n",
    "    num_epoch=60,\n",
    ").train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reconstruction(image):\n",
    "    model.eval()\n",
    "\n",
    "    image = torch.unsqueeze(image, 0)\n",
    "    with torch.no_grad():\n",
    "        recon = model(image.to(device))\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2)\n",
    "    axes[0].imshow(image[0][0])\n",
    "    axes[0].set_title('Original')\n",
    "    axes[1].imshow(recon[0][0].cpu().numpy())\n",
    "    axes[1].set_title('Reconstructed')\n",
    "    for ax in axes:\n",
    "        ax.axis('off')\n",
    "\n",
    "plot_reconstruction(training_set[0][0])\n",
    "plot_reconstruction(testing_normal_set[10][0])\n",
    "plot_reconstruction(testing_outlier_set[10][0])\n",
    "plot_reconstruction(testing_outlier_set[20][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def validate_model(model):\n",
    "    y_score = []\n",
    "    y_true = []\n",
    "    model.eval()\n",
    "    testing_loader = DataLoader(testing_set, batch_size=256)\n",
    "    for data, target in tqdm(testing_loader, total=len(testing_loader), unit='batch'):\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            recon = model(data)\n",
    "            true = (target == NORMAL_TARGET_CLASS).cpu().numpy()\n",
    "\n",
    "            # Lower MSE = higher score, so negate the value\n",
    "            score = -((recon - data)**2).mean(dim=(1, 2, 3)).cpu().numpy()\n",
    "\n",
    "        y_true.extend(true)\n",
    "        y_score.extend(score)\n",
    "\n",
    "    return np.asarray(y_true), np.asarray(y_score)\n",
    "\n",
    "y_true, y_score = validate_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "plt.plot(\n",
    "    *roc_curve(y_true, y_score)[:2],\n",
    "    label=f'AE (AUC = {roc_auc_score(y_true, y_score):g})'\n",
    ")\n",
    "plt.legend()\n",
    "plt.gca().set_box_aspect(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "memae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
